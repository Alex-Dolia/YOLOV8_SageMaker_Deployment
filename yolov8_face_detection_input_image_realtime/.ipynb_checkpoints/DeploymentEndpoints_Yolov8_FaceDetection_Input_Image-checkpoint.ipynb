{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f2c3b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics==8.1.45 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (8.1.45)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ultralytics==8.1.45) (3.9.1)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ultralytics==8.1.45) (4.8.1.78)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ultralytics==8.1.45) (10.2.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ultralytics==8.1.45) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ultralytics==8.1.45) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ultralytics==8.1.45) (1.14.0)\n",
      "Requirement already satisfied: torch>=1.8.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ultralytics==8.1.45) (2.2.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ultralytics==8.1.45) (0.17.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ultralytics==8.1.45) (4.66.4)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ultralytics==8.1.45) (6.0.0)\n",
      "Requirement already satisfied: py-cpuinfo in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ultralytics==8.1.45) (9.0.0)\n",
      "Requirement already satisfied: thop>=0.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ultralytics==8.1.45) (0.1.1.post2209072238)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ultralytics==8.1.45) (1.5.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from ultralytics==8.1.45) (0.13.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics==8.1.45) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics==8.1.45) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics==8.1.45) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics==8.1.45) (1.4.5)\n",
      "Requirement already satisfied: numpy>=1.23 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics==8.1.45) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics==8.1.45) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics==8.1.45) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics==8.1.45) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics==8.1.45) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics==8.1.45) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics==8.1.45) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics==8.1.45) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics==8.1.45) (2024.7.4)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics==8.1.45) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics==8.1.45) (4.12.2)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics==8.1.45) (1.13.0)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics==8.1.45) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics==8.1.45) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics==8.1.45) (2024.6.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics==8.1.45) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics==8.1.45) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sympy->torch>=1.8.0->ultralytics==8.1.45) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics==8.1.45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c3366d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): - WARNING conda.models.version:get_matcher(546): Using .* with relational operator is superfluous and deprecated and will be removed in a future version of conda. Your spec was 1.7.1.*, but conda is ignoring the .* and treating it as 1.7.1\n",
      "done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.3.1\n",
      "  latest version: 24.7.1\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c conda-forge conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=24.7.1\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/ec2-user/anaconda3/envs/pytorch_p310\n",
      "\n",
      "  added / updated specs:\n",
      "    - omegaconf\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    certifi-2024.8.30          |     pyhd8ed1ab_0         160 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         160 KB\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  certifi                             2024.7.4-pyhd8ed1ab_0 --> 2024.8.30-pyhd8ed1ab_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "                                                                                \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install omegaconf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be128e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab15239a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade pip setuptools wheel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c875d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf56b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import setuptools\n",
    "setuptools.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dae059-e6d3-413f-8916-68a896c2a829",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install opencv-python==4.8.1.78"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e25aca-d7fc-4f72-8c0a-b53d4591702c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from src import inference as inf\n",
    "from matplotlib import pyplot as plt\n",
    "import boto3\n",
    "import json, cv2\n",
    "model_dir = \"\"\n",
    "model = inf.model_fn(model_dir)\n",
    "#####################################################\n",
    "import json\n",
    "import base64\n",
    "\n",
    "# load image\n",
    "with open('input/frame226.jpg', 'rb') as image_file:\n",
    "    image_base64 = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "# create payload \n",
    "payload = json.dumps({\n",
    "    'instances': [{\n",
    "        'b64': image_base64,\n",
    "    }]\n",
    "})\n",
    "#####################################################\n",
    "content_type = 'application/json'\n",
    "input_data = inf.input_fn(payload, content_type)\n",
    "prediction_output = inf.predict_fn(input_data, model)\n",
    "str_result = inf.output_fn(prediction_output, content_type)\n",
    "result = json.loads(str_result)\n",
    "print(\"status: \", result[\"status\"])\n",
    "print(\"boxes: \", result[\"boxes\"])\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "########################################\n",
    "frame = cv2.imread('input/frame226.jpg')\n",
    "#frame = cv2.imread('input/content-recognition-live-ireland_00a22e2a-fe33-46e4-8415-57daa565da7f_frame138.jpg')\n",
    "print(\"frame.shape: \", frame.shape)\n",
    "\n",
    "\n",
    "\n",
    "x1,y1,x2,y2, conf, cl = result[\"boxes\"][0]\n",
    "x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "resized_image = frame.copy()    \n",
    "image_height, image_width, _ = resized_image.shape\n",
    "model_height, model_width = 300, 300\n",
    "x_ratio = image_width/model_width\n",
    "y_ratio = image_height/model_height\n",
    "resized_image = cv2.resize(resized_image, (model_height, model_width))\n",
    "\n",
    "face = resized_image[y1:y2, x1:x2].copy()\n",
    "print(\"face.shape: \", face.shape)\n",
    "plt.imshow(face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7d8116-5c66-4e95-82d5-24bfc54336bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, sagemaker, subprocess, boto3\n",
    "from datetime import datetime\n",
    "from sagemaker import s3\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "from sagemaker.deserializers import JSONDeserializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250de41b-f47b-47e7-b34a-44161193bd48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4530ea-f8b6-474a-8d7d-2df44beab5ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create the model artifacts \n",
    "bashCommand = \"tar -czf  model.tar.gz src model\"\n",
    "process = subprocess.Popen(bashCommand.split(), stdout=subprocess.PIPE)\n",
    "output, error = process.communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bebe5c-f2d1-425a-9f28-323b48d2cd9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "role = get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "model_name = \"yolov8n-face.pt\"\n",
    "model_data = 'model.tar.gz'\n",
    "model = PyTorchModel(entry_point='inference.py',\n",
    "                     model_data=model_data, \n",
    "                     framework_version='1.12', \n",
    "                     py_version='py38',\n",
    "                     role=role,\n",
    "                     source_dir = \"src\",\n",
    "                     env={'TS_MAX_RESPONSE_SIZE':'20000000', 'YOLOV8_MODEL': model_name},\n",
    "                     sagemaker_session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f373623c-34ad-429b-b37d-2308ea67a63f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ENDPOINT_NAME = 'yolov8-pytorch-facedetection-ADOLIA' + str(datetime.utcnow().strftime('%Y-%m-%d-%H-%M-%S-%f'))\n",
    "\n",
    "# Store the endpoint name in the history to be accessed by 2_TestEndpoint.ipynb notebook\n",
    "# We dnt have 2_TestEndpoint.ipynb in this project\n",
    "%store ENDPOINT_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1419a6-db87-4e31-b22b-2804d00f8c8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ENDPOINT_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60738f3-c08d-485a-a0dd-48fdf61e0c93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://docs.aws.amazon.com/sagemaker/latest/dg/async-inference-troubleshooting.html\n",
    "INSTANCE_TYPE = 'ml.g5.xlarge'\n",
    "print(\"ENDPOINT_NAME: \", ENDPOINT_NAME)\n",
    "print(\"INSTANCE_TYPE: \", INSTANCE_TYPE)\n",
    "\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "predictor = model.deploy(initial_instance_count = 1,\n",
    "                         instance_type          = INSTANCE_TYPE,\n",
    "                         serializer             = JSONDeserializer(),\n",
    "                         deserializer           = JSONDeserializer(),\n",
    "                         endpoint_name          = ENDPOINT_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc32049c-82df-4312-9e05-a581326eb1f3",
   "metadata": {},
   "source": [
    "# Invoke Endpoint: Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5530835-f122-4a74-be1c-ec95e09e2ac5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%store -r ENDPOINT_NAME\n",
    "sm_client = boto3.client(service_name=\"sagemaker\")\n",
    "\n",
    "# Restore the endpoint name stored in the 2_DeployEndpoint.ipynb notebook\n",
    "%store -r ENDPOINT_NAME\n",
    "print(f'Endpoint Name: {ENDPOINT_NAME}')\n",
    "\n",
    "endpoint_created = False\n",
    "while True:\n",
    "    response = sm_client.list_endpoints()\n",
    "    for ep in response['Endpoints']:\n",
    "        print(f\"Endpoint Status = {ep['EndpointStatus']}\")\n",
    "        if ep['EndpointName']==ENDPOINT_NAME and ep['EndpointStatus']=='InService':\n",
    "            endpoint_created = True\n",
    "            break\n",
    "    if endpoint_created:\n",
    "        break\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9677dbc2-f3ee-478a-a967-f06d65c276be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Alternatively, you can provide the input_path parameter for predict_async with the s3 path for the input data\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "#####################################################\n",
    "import json\n",
    "import base64\n",
    "\n",
    "# load image\n",
    "with open('input/frame226.jpg', 'rb') as image_file:\n",
    "    image_base64 = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "# create payload \n",
    "payload = json.dumps({\n",
    "    'instances': [{\n",
    "        'b64': image_base64,\n",
    "    }]\n",
    "})\n",
    "#####################################################\n",
    "\n",
    "runtime = boto3.client('sagemaker-runtime')\n",
    "\n",
    "response_ad = runtime.invoke_endpoint(\n",
    "    EndpointName=ENDPOINT_NAME,\n",
    "    ContentType='application/json',\n",
    "    Body=payload.encode('utf-8') \n",
    ")\n",
    "\n",
    "# Parse the response body\n",
    "response_body_ad = response_ad['Body'].read().decode('utf-8')\n",
    "result_ad = json.loads(response_body_ad)\n",
    "print(\"status: \", result_ad[\"status\"])\n",
    "print(\"boxes: \", result_ad[\"boxes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2a6f05-a96b-441d-8e84-4ab6caa4fb18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# original image that I download from s3 has already bounding box (largest bounding box) and\n",
    "# face detector add another bounding box (smaller box)\n",
    "\n",
    "orig_image = np.array(result_ad[\"orig_image\"]).astype(np.uint8)\n",
    "\n",
    "image_height, image_width, _ = orig_image.shape\n",
    "model_height, model_width = 300, 300\n",
    "x_ratio = image_width/model_width\n",
    "y_ratio = image_height/model_height\n",
    "\n",
    "if 'boxes' in result_ad:\n",
    "    for idx,(x1,y1,x2,y2,conf,lbl) in enumerate(result_ad['boxes']):\n",
    "        print(\"x1,y1,x2,y2: \", x1,y1,x2,y2)\n",
    "        # Draw Bounding Boxes\n",
    "        x1, x2 = int(x_ratio*x1), int(x_ratio*x2)\n",
    "        y1, y2 = int(y_ratio*y1), int(y_ratio*y2)\n",
    "        color = (random.randint(10,255), random.randint(10,255), random.randint(10,255))\n",
    "        cv2.rectangle(orig_image, (x1,y1), (x2,y2), color, 4)\n",
    "        print(\"left top point: \", (x1,y1), \", right bottom point: \", (x2,y2))\n",
    "        print(\"detected object class: \", lbl)\n",
    "        print(\"detection confidence: \", conf)\n",
    "        cv2.putText(orig_image, f\"Class: {int(lbl)}\", (x1,y1-40), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2, cv2.LINE_AA)\n",
    "        cv2.putText(orig_image, f\"Conf: {int(conf*100)}\", (x1,y1-10), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2, cv2.LINE_AA)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(orig_image, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac5a748-1d18-4ae2-a9f5-1f45d5a99692",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor.delete_model()\n",
    "predictor.delete_endpoint() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2da65f-807a-4cf2-975a-3025ad978b3d",
   "metadata": {},
   "source": [
    "To make a compressed tar ball of the current directory <br>\n",
    "tar -czvf yolov8_face_detection_input_s3_realtime.tar.gz .  <br>\n",
    "Unzip: <br>\n",
    "tar -xzvf yolov8_face_detection_input_s3_realtime.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137fb8ea-c00c-47d7-911f-8db36be4c13a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
